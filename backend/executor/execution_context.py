import os
from dotenv import load_dotenv
from openai import OpenAI
import httpx

class ExecutionContext:
    def __init__(self, use_mock: bool = False):
        load_dotenv()

        self.use_mock = use_mock

        # ä»ç¯å¢ƒå˜é‡è¯»å– API Key å’Œæ¨¡å‹é…ç½®
        self.api_key = os.getenv("API_KEY", "")

        self.fast_model = os.getenv("FAST_MODEL", "gpt-3.5-turbo")
        self.slow_model = os.getenv("SLOW_MODEL", "gpt-4")
        self.executor_model = os.getenv("Executor_MODEL", "gpt-4")

        # åˆ›å»ºhttpxå®¢æˆ·ç«¯è§£å†³ç‰ˆæœ¬å…¼å®¹æ€§é—®é¢˜
        self.http_client = httpx.Client() if self.api_key else None

        # åˆå§‹åŒ–ä¸¤ä¸ªç‹¬ç«‹çš„ OpenAI å®¢æˆ·ç«¯ï¼ˆå¯é€‰ï¼šæœªæ¥æ”¯æŒä¸åŒ Keyï¼‰
        self.fast_client = OpenAI(api_key=self.api_key, http_client=self.http_client) if self.api_key else None
        self.slow_client = OpenAI(api_key=self.api_key, http_client=self.http_client) if self.api_key else None
        self.executor_client = OpenAI(api_key=self.api_key, http_client=self.http_client) if self.api_key else None

    def get_client(self, role: str = "fast") -> OpenAI:
        if self.use_mock:
            print(f"âœ… ä½¿ç”¨ Mock æ¨¡å¼ï¼Œè·³è¿‡çœŸå®è°ƒç”¨ã€‚({role})")
            return None  # æˆ–è¿”å› mock client

        if role == "fast":
            return self.fast_client
        elif role == "slow":
            return self.slow_client
        elif role == "executor":
            return self.executor_client
        else:
            raise ValueError(f"æœªçŸ¥è§’è‰²ç±»å‹: {role}")

    def get_model(self, role: str = "fast") -> str:
        if role == "fast":
            return self.fast_model
        elif role == "slow":
            return self.slow_model
        elif role == "executor":
            return self.executor_model
        else:
            raise ValueError(f"æœªçŸ¥è§’è‰²ç±»å‹: {role}")

    def test_api(self) -> bool:
        """
        æµ‹è¯• client æ˜¯å¦èƒ½æ­£å¸¸è¿æ¥ï¼ˆé»˜è®¤æµ‹è¯• fast æ¨¡å‹ï¼‰
        """
        if not self.fast_client:
            print("âŒ API Keyæœªé…ç½®")
            return False
            
        try:
            print(f"ğŸ” æ­£åœ¨æµ‹è¯• OpenAI APIï¼šæ¨¡å‹ = {self.fast_model}")
            response = self.fast_client.chat.completions.create(
                model=self.fast_model,
                messages=[{"role": "user", "content": "ä½ å¥½ï¼Œ1+1=ï¼Ÿ"}],
                timeout=5
            )
            print("âœ… API å“åº”æˆåŠŸ")
            print("ğŸ’¬ è¿”å›å†…å®¹:", response.choices[0].message.content)
            return True
        except Exception as e:
            print(f"âŒ API è°ƒç”¨å¤±è´¥ï¼š{e}")
            return False

    def __del__(self):
        # æ¸…ç†httpå®¢æˆ·ç«¯
        if self.http_client:
            self.http_client.close()